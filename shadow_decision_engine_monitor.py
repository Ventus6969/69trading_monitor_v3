"""
å½±å­æ¨¡å¼æ±ºç­–é‚è¼¯ - ç›£æ§ä¸»æ©Ÿç‰ˆæœ¬
ä¿®æ”¹å°å…¥è·¯å¾‘ï¼Œé©é…ç›£æ§ä¸»æ©Ÿç’°å¢ƒ
=============================================================================
"""
import logging
import time
from datetime import datetime
from typing import Dict, Any, Optional, Tuple

# è¨­ç½®logger
logger = logging.getLogger(__name__)

class ShadowModeDecisionEngine:
    """å½±å­æ¨¡å¼æ±ºç­–å¼•æ“ - ç›£æ§ä¸»æ©Ÿç‰ˆæœ¬"""
    
    def __init__(self):
        self.min_data_for_ml = 50  # æœ€å°‘æ•¸æ“šé‡æ‰å•Ÿç”¨MLæ¨¡å‹
        self.decision_threshold = 0.7  # æ±ºç­–é–¾å€¼
        self.confidence_threshold = 0.6  # ä¿¡å¿ƒåº¦é–¾å€¼
        
        # åŸºæ–¼å·²çŸ¥äº¤æ˜“çš„æ´å¯Ÿå»ºç«‹åˆå§‹è¦å‰‡
        self.strategy_rules = self._initialize_strategy_rules()
        
        logger.info("å½±å­æ¨¡å¼æ±ºç­–å¼•æ“å·²åˆå§‹åŒ– (ç›£æ§ä¸»æ©Ÿç‰ˆæœ¬)")
    
    def _initialize_strategy_rules(self) -> Dict[str, Dict]:
        """åˆå§‹åŒ–ç­–ç•¥è¦å‰‡"""
        return {
            # é«˜é¢¨éšªçµ„åˆ
            'high_risk_combinations': [
                {'signal_type': 'consolidation_buy', 'opposite': 2, 'risk_level': 'HIGH'},
                {'signal_type': 'reversal_buy', 'opposite': 2, 'risk_level': 'HIGH'},
            ],
            
            # é«˜å“è³ªçµ„åˆ
            'high_quality_combinations': [
                {'signal_type': 'breakdown_sell', 'opposite': 0, 'risk_level': 'LOW'},
            ],
            
            # ç­–ç•¥åå¥½
            'strategy_preferences': {
                'breakout_buy': {'default_confidence': 0.5, 'note': 'çªç ´ç­–ç•¥ï¼Œä¸­ç­‰é¢¨éšª'},
                'consolidation_buy': {'default_confidence': 0.3, 'note': 'æ•´ç†ç­–ç•¥ï¼Œè¼ƒé«˜é¢¨éšª'},
                'reversal_buy': {'default_confidence': 0.4, 'note': 'åè½‰ç­–ç•¥ï¼Œä¸­ç­‰é¢¨éšª'},
                'bounce_buy': {'default_confidence': 0.5, 'note': 'åå½ˆç­–ç•¥ï¼Œä¸­ç­‰é¢¨éšª'},
                'trend_sell': {'default_confidence': 0.6, 'note': 'è¶¨å‹¢ç­–ç•¥ï¼Œè¼ƒä½é¢¨éšª'},
                'breakdown_sell': {'default_confidence': 0.7, 'note': 'ç ´åº•ç­–ç•¥ï¼Œä½é¢¨éšª'},
                'high_sell': {'default_confidence': 0.5, 'note': 'é«˜ä½ç­–ç•¥ï¼Œä¸­ç­‰é¢¨éšª'},
                'reversal_sell': {'default_confidence': 0.4, 'note': 'åè½‰ç­–ç•¥ï¼Œä¸­ç­‰é¢¨éšª'}
            }
        }
    
    def make_shadow_decision(self, session_id: str, signal_id: int, 
                           features: Dict[str, Any], signal_data: Dict[str, Any]) -> Dict[str, Any]:
        """ç”Ÿæˆå½±å­æ¨¡å¼æ±ºç­–å»ºè­°"""
        try:
            logger.info(f"é–‹å§‹å½±å­æ¨¡å¼æ±ºç­–åˆ†æ - signal_id: {signal_id}")
            
            # æª¢æŸ¥æ˜¯å¦æœ‰è¶³å¤ æ•¸æ“šä½¿ç”¨MLæ¨¡å‹
            if self._should_use_ml_model():
                decision_result = self._ml_based_decision(features, signal_data)
                decision_result['decision_method'] = 'ML_MODEL'
            else:
                decision_result = self._rule_based_decision(features, signal_data)
                decision_result['decision_method'] = 'RULE_BASED'
            
            # è¨˜éŒ„æ±ºç­–çµæœ
            self._record_shadow_decision(session_id, signal_id, decision_result, features, signal_data)
            
            # è©³ç´°æ—¥èªŒè¨˜éŒ„
            self._log_decision_details(signal_id, decision_result, signal_data)
            
            return decision_result
            
        except Exception as e:
            logger.error(f"å½±å­æ¨¡å¼æ±ºç­–æ™‚å‡ºéŒ¯: {str(e)}")
            return self._get_fallback_decision(signal_data, str(e))
    
    def _should_use_ml_model(self) -> bool:
        """æª¢æŸ¥æ˜¯å¦æ‡‰è©²ä½¿ç”¨MLæ¨¡å‹"""
        try:
            # ç›£æ§ä¸»æ©Ÿç‰ˆæœ¬ï¼šæš«æ™‚ç¸½æ˜¯ä½¿ç”¨è¦å‰‡æ±ºç­–
            return False
        except Exception as e:
            logger.warning(f"æª¢æŸ¥MLæ¨¡å‹å¯ç”¨æ€§æ™‚å‡ºéŒ¯: {str(e)}ï¼Œå›é€€åˆ°è¦å‰‡æ±ºç­–")
            return False
    
    def _rule_based_decision(self, features: Dict[str, Any], signal_data: Dict[str, Any]) -> Dict[str, Any]:
        """åŸºæ–¼è¦å‰‡çš„æ±ºç­–é‚è¼¯"""
        signal_type = signal_data.get('signal_type')
        opposite = signal_data.get('opposite', 0)
        symbol = signal_data.get('symbol', '')
        
        # 1. æª¢æŸ¥æ˜¯å¦ç‚ºå·²çŸ¥é«˜é¢¨éšªçµ„åˆ
        for high_risk in self.strategy_rules['high_risk_combinations']:
            if (signal_type == high_risk['signal_type'] and 
                opposite == high_risk['opposite']):
                return {
                    'recommendation': 'SKIP',
                    'confidence': 0.3,
                    'reason': f'å·²çŸ¥é«˜é¢¨éšªçµ„åˆ: {signal_type} + opposite={opposite}',
                    'risk_level': 'HIGH',
                    'execution_probability': 0.3,
                    'trading_probability': 0.3,
                    'suggested_price_adjustment': 0.0
                }
        
        # 2. æª¢æŸ¥æ˜¯å¦ç‚ºå·²çŸ¥é«˜å“è³ªçµ„åˆ
        for high_quality in self.strategy_rules['high_quality_combinations']:
            if (signal_type == high_quality['signal_type'] and 
                opposite == high_quality['opposite']):
                return {
                    'recommendation': 'EXECUTE',
                    'confidence': 0.8,
                    'reason': f'å·²çŸ¥é«˜å“è³ªçµ„åˆ: {signal_type} + opposite={opposite}',
                    'risk_level': 'LOW',
                    'execution_probability': 0.8,
                    'trading_probability': 0.8,
                    'suggested_price_adjustment': 0.0
                }
        
        # 3. åŸºæ–¼ç­–ç•¥åå¥½è©•ä¼°
        strategy_pref = self.strategy_rules['strategy_preferences'].get(signal_type, {})
        base_confidence = strategy_pref.get('default_confidence', 0.5)
        
        # 4. åŸºæ–¼oppositeå€¼èª¿æ•´ä¿¡å¿ƒåº¦
        opposite_adjustment = self._calculate_opposite_adjustment(opposite)
        final_confidence = max(0.1, min(0.9, base_confidence + opposite_adjustment))
        
        # 5. ç”Ÿæˆæ±ºç­–
        recommendation = 'EXECUTE' if final_confidence >= self.confidence_threshold else 'SKIP'
        
        return {
            'recommendation': recommendation,
            'confidence': final_confidence,
            'reason': f"ç­–ç•¥è©•ä¼°: {strategy_pref.get('note', 'æœªçŸ¥ç­–ç•¥')}, oppositeèª¿æ•´: {opposite_adjustment:+.2f}",
            'risk_level': 'MEDIUM',
            'execution_probability': final_confidence,
            'trading_probability': final_confidence,
            'suggested_price_adjustment': 0.0
        }
    
    def _calculate_opposite_adjustment(self, opposite: int) -> float:
        """åŸºæ–¼oppositeå€¼è¨ˆç®—ä¿¡å¿ƒåº¦èª¿æ•´"""
        if opposite == 0:
            return 0.1  # ç•¶å‰æ”¶ç›¤åƒ¹ï¼Œç›¸å°è¼ƒå¥½
        elif opposite == 1:
            return 0.0  # å‰æ ¹æ”¶ç›¤åƒ¹ï¼Œä¸­æ€§
        elif opposite == 2:
            return -0.1  # å‰æ ¹é–‹ç›¤åƒ¹ï¼Œå·²çŸ¥å•é¡Œè¼ƒå¤š
        else:
            return -0.1  # æœªçŸ¥å€¼ï¼Œä¿å®ˆè™•ç†
    
    def _ml_based_decision(self, features: Dict[str, Any], signal_data: Dict[str, Any]) -> Dict[str, Any]:
        """åŸºæ–¼MLæ¨¡å‹çš„æ±ºç­–é‚è¼¯"""
        logger.info("MLæ¨¡å‹åŠŸèƒ½é–‹ç™¼ä¸­ï¼Œæš«æ™‚ä½¿ç”¨å¢å¼·è¦å‰‡é‚è¼¯")
        
        # æš«æ™‚èª¿ç”¨è¦å‰‡æ±ºç­–ï¼Œä½†æé«˜ä¿¡å¿ƒåº¦
        rule_result = self._rule_based_decision(features, signal_data)
        
        # MLç‰ˆæœ¬çš„å¢å¼·
        rule_result['confidence'] = min(1.0, rule_result['confidence'] + 0.1)
        rule_result['reason'] += ' (MLå¢å¼·ç‰ˆ)'
        
        return rule_result
    
    def _record_shadow_decision(self, session_id: str, signal_id: int, 
                               decision_result: Dict[str, Any], features: Dict[str, Any], 
                               signal_data: Dict[str, Any]) -> bool:
        """è¨˜éŒ„å½±å­æ±ºç­–åˆ°è³‡æ–™åº«"""
        try:
            # ç›£æ§ä¸»æ©Ÿç‰ˆæœ¬ï¼šå¯ä»¥è¨˜éŒ„åˆ°æœ¬åœ°æ•¸æ“šåº«
            # ä½†æš«æ™‚ä¸å¯¦ç¾ï¼Œé¿å…å¾ªç’°ä¾è³´
            logger.info(f"å½±å­æ±ºç­–è¨˜éŒ„ - signal_id: {signal_id}, å»ºè­°: {decision_result.get('recommendation')}")
            return True
            
        except Exception as e:
            logger.error(f"è¨˜éŒ„å½±å­æ±ºç­–æ™‚å‡ºéŒ¯: {str(e)}")
            return False
    
    def _log_decision_details(self, signal_id: int, decision_result: Dict[str, Any], 
                            signal_data: Dict[str, Any]):
        """è©³ç´°è¨˜éŒ„æ±ºç­–æ—¥èªŒ"""
        signal_type = signal_data.get('signal_type')
        opposite = signal_data.get('opposite')
        symbol = signal_data.get('symbol')
        
        logger.info(f"ğŸ¤– å½±å­æ¨¡å¼æ±ºç­–å®Œæˆ:")
        logger.info(f"   ä¿¡è™Ÿ: {signal_type} | opposite: {opposite} | äº¤æ˜“å°: {symbol}")
        logger.info(f"   å»ºè­°: {decision_result.get('recommendation')}")
        logger.info(f"   ä¿¡å¿ƒåº¦: {decision_result.get('confidence', 0):.1%}")
        logger.info(f"   åŸ·è¡Œæ¦‚ç‡: {decision_result.get('execution_probability', 0):.1%}")
        logger.info(f"   ç†ç”±: {decision_result.get('reason')}")
        logger.info(f"   æ–¹æ³•: {decision_result.get('decision_method')}")
    
    def _get_fallback_decision(self, signal_data: Dict[str, Any], error_msg: str) -> Dict[str, Any]:
        """éŒ¯èª¤æ™‚çš„å›é€€æ±ºç­–"""
        return {
            'recommendation': 'EXECUTE',
            'confidence': 0.5,
            'reason': f'å½±å­æ¨¡å¼éŒ¯èª¤å›é€€: {error_msg}',
            'risk_level': 'UNKNOWN',
            'execution_probability': 0.5,
            'trading_probability': 0.5,
            'suggested_price_adjustment': 0.0,
            'decision_method': 'FALLBACK'
        }
    
    def get_shadow_statistics(self) -> Dict[str, Any]:
        """ç²å–å½±å­æ¨¡å¼çµ±è¨ˆ"""
        try:
            return {
                'total_decisions': 0,
                'ml_ready': False,
                'data_progress': f"0/{self.min_data_for_ml}",
                'current_mode': 'RULE_BASED'
            }
            
        except Exception as e:
            logger.error(f"ç²å–å½±å­æ¨¡å¼çµ±è¨ˆæ™‚å‡ºéŒ¯: {str(e)}")
            return {'error': str(e)}

# å‰µå»ºå…¨å±€å½±å­æ±ºç­–å¼•æ“å¯¦ä¾‹
shadow_decision_engine = ShadowModeDecisionEngine()
